minValueRow <- k_summary[k_summary[,2]==minVal, 1]
minValK<-minValueRow
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10],  k=minValK)
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, c(1, 2)], col = as.factor(index_valid), pch = as.numeric(resultValid1))
minValK
minValK[1]
minValK[1,1]
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10],  k=minValK[1])
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, c(1, 2)], col = as.factor(index_valid), pch = as.numeric(resultValid1))
plot(k_summary)
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
heart_data
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6)]
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=3)
result
plot(test[, c(1, 2)], col = as.factor(index_test), pch = as.numeric(result))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(result, heart_data[index_test,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#To see how the k-nearest neighbour classification performs as a function of k we can write a for loop:
kmax <- 50
k <- 1:kmax
p <- rep(0, kmax)
ntest <- nrow(test)
k_summary <- cbind(k, p)
colnames(k_summary) <- c("k","% misclassified")
for(i in 1:kmax)
{
result <- knn(train, test, cl = heart_data[index_train, 10], k = i)
class_agree <- table(result, heart_data[index_test,10])
sum_agree <- sum(diag(class_agree))
k_summary[i, 2] <- (ntest - sum_agree) / ntest
}
k_summary
dim(k_summary)
k_summary[1:10, ]
plot(k_summary)
######## NOT FINISHED ###################
minVal<-min(k_summary[,2])
minVal
minValueRow <- k_summary[k_summary[,2]==minVal, 1]
minValK<-minValueRow
minValK[1]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10],  k=minValK[1])
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, c(1, 2)], col = as.factor(index_valid), pch = as.numeric(resultValid1))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, simT[index_valid,3])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10],k=3)  #k=minValK[1])
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, c(1, 2)], col = as.factor(index_valid), pch = as.numeric(resultValid1))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, simT[index_valid,3])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
plot(valid[, c(1,3,4,6,9)], col = as.factor(index_valid), pch = as.numeric(resultValid1))
plot(valid[, ], col = as.factor(index_valid), pch = as.numeric(resultValid1))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, simT[index_valid,3])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
heart_data
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6,9)]
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=3)
result
plot(test[, c(1, 2)], col = as.factor(index_test), pch = as.numeric(result))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(result, heart_data[index_test,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#To see how the k-nearest neighbour classification performs as a function of k we can write a for loop:
kmax <- 50
k <- 1:kmax
p <- rep(0, kmax)
ntest <- nrow(test)
k_summary <- cbind(k, p)
colnames(k_summary) <- c("k","% misclassified")
for(i in 1:kmax)
{
result <- knn(train, test, cl = heart_data[index_train, 10], k = i)
class_agree <- table(result, heart_data[index_test,10])
sum_agree <- sum(diag(class_agree))
k_summary[i, 2] <- (ntest - sum_agree) / ntest
}
k_summary
dim(k_summary)
k_summary[1:10, ]
plot(k_summary)
######## NOT FINISHED ###################
minVal<-min(k_summary[,2])
minVal
minValueRow <- k_summary[k_summary[,2]==minVal, 1]
minValK<-minValueRow
minValK[1]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10],k=3)  #k=minValK[1])
resultValid1
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10],k=3)  #k=minValK[1])
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, ], col = as.factor(index_valid), pch = as.numeric(resultValid1))
library(MASS)
#install.packages("FNN")
library(FNN)
library(dplyr)
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
heart_data
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6,9)]
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=3)
result
plot(knn(train, test, cl = heart_data[index_train, 10], k=3))
library(MASS)
#install.packages("FNN")
library(FNN)
library(dplyr)
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
heart_data
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6,9)]
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=3)
result
plot(test[, c(1, 2)], col = as.factor(index_test), pch = as.numeric(result))
plot(test[, c], col = as.factor(index_test), pch = as.numeric(result))
plot(test[, ], col = as.factor(index_test), pch = as.numeric(result))
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
result <- knn(train, test, cl = heart_data[index_train, 10], k=11)
result
plot(test[, ], col = as.factor(index_test), pch = as.numeric(result))
result <- knn(train, test, cl = heart_data[index_train, 10], k=30)
result <- knn(train, test, cl = heart_data[index_train, 10], k=20)
result <- knn(train, test, cl = heart_data[index_train, 10], k=11)
library(MASS)
#install.packages("FNN")
library(FNN)
library(dplyr)
#installed.packages("class")
#Simulating Data
muA <- c(0, 0)
muB <- c(5, 3)
sigA <- matrix(c(10, 3, 3, 2), nrow = 2, ncol = 2)
sigB <- matrix(c(12, 2, 2, 15), nrow = 2, ncol = 2)
simA <- mvrnorm(900, muA, sigA)
simB <- mvrnorm(900, muB, sigB)
simT <- rbind(simA,simB)
#add a column to simT that indicates the class membership of each observation
class_ind <- rep(c(1, 2), each = 900)
simT <- cbind(simT, class_ind)
plot(simT[,1], simT[,2], col = as.factor(simT[, 3]))
#Training and Test Data
#We will use a split whereby 1/3 of the data will be used for training, 1/3 of the data will be used
#for testing, and 1/3 for validation
index_train <- c(1:300, 1:300 + 900) #First third of simA and simB
index_test <- c(1:300 + 300, 1:300 + 900 + 300) #Second third of simA and simB
index_valid <- c(1:300 + 600, 1:300 + 900 + 600) #Final third of simA and simB
train <- simT[index_train, 1:2]
test <- simT[index_test, 1:2]
valid <- simT[index_valid, 1:2]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = simT[index_train, 3], k=3)
result
plot(test[, c(1, 2)], col = as.factor(index_test), pch = as.numeric(result))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(result, simT[index_test,3])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#To see how the k-nearest neighbour classification performs as a function of k we can write a for loop:
kmax <- 50
k <- 1:kmax
p <- rep(0, kmax)
ntest <- nrow(test)
k_summary <- cbind(k, p)
colnames(k_summary) <- c("k","% misclassified")
for(i in 1:kmax)
{
result <- knn(train, test, cl = simT[index_train, 3], k = i)
class_agree <- table(result, simT[index_test,3])
sum_agree <- sum(diag(class_agree))
k_summary[i, 2] <- (ntest - sum_agree) / ntest
}
k_summary
dim(k_summary)
k_summary[1:10, ]
plot(k_summary)
######## NOT FINISHED ###################
minVal<-min(k_summary[,2])
minVal
minValueRow <- k_summary[k_summary[,2]==minVal, 1]
minValK<-minValueRow
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
resultValid1 <- knn(train, valid, cl = simT[index_train, 3],  k=minValK)
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, c(1, 2)], col = as.factor(index_valid), pch = as.numeric(resultValid1))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, simT[index_valid,3])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = simT[index_train, 3], k=3)
result
resultValid1 <- knn(train, valid, cl = simT[index_train, 3],  k=minValK)
resultValid1
library(MASS)
#install.packages("FNN")
library(FNN)
library(dplyr)
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
heart_data
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6,9)]
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
?knn
result <- knn(train, test, cl = heart_data[index_train, 10], k=11)
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=11)
result
plot(test[,], col = as.factor(index_test), pch = as.numeric(result))
result
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(result, heart_data[index_test,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#To see how the k-nearest neighbour classification performs as a function of k we can write a for loop:
kmax <- 50
k <- 1:kmax
p <- rep(0, kmax)
ntest <- nrow(test)
k_summary <- cbind(k, p)
colnames(k_summary) <- c("k","% misclassified")
for(i in 1:kmax)
{
result <- knn(train, test, cl = heart_data[index_train, 10], k = i)
class_agree <- table(result, heart_data[index_test,10])
sum_agree <- sum(diag(class_agree))
k_summary[i, 2] <- (ntest - sum_agree) / ntest
}
k_summary
dim(k_summary)
k_summary[1:10, ]
plot(k_summary)
######## NOT FINISHED ###################
minVal<-min(k_summary[,2])
minVal
minValueRow <- k_summary[k_summary[,2]==minVal, 1]
minValK<-minValueRow
minValK[1]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10], k=minValK[1])
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, ], col = as.factor(index_valid), pch = as.numeric(resultValid1))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, simT[index_valid,3])
class_agree
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, heart_data[index_valid,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
plot(resultValid1)
library(MASS)
#install.packages("FNN")
library(FNN)
library(dplyr)
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
heart_data<-scale(heart_data)
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6,9)]
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=11)
result
plot(test[,], col = as.factor(index_test), pch = as.numeric(result))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(result, heart_data[index_test,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#Read csv file
heart_data<-read.csv("C:/Users/carty/Documents/Third Year MSISS/MLA Assignment/heart_data.csv")
summary(heart_data)
dim(heart_data)
#Continuous Variables
contVar<-heart_data[, c(1,3,4,6,9)]
contVar<-scale(contVar)
#for testing, and 1/3 for validation
index_train <- c(1:90) #First third
index_test <- c(91:180) #Second third
index_valid <- c(181:270) #Final third
train <- contVar[index_train, ]
test <- contVar[index_test, ]
valid <- contVar[index_valid, ]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
result <- knn(train, test, cl = heart_data[index_train, 10], k=11)
result
plot(test[,], col = as.factor(index_test), pch = as.numeric(result))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(result, heart_data[index_test,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
#To see how the k-nearest neighbour classification performs as a function of k we can write a for loop:
kmax <- 50
k <- 1:kmax
p <- rep(0, kmax)
ntest <- nrow(test)
k_summary <- cbind(k, p)
colnames(k_summary) <- c("k","% misclassified")
for(i in 1:kmax)
{
result <- knn(train, test, cl = heart_data[index_train, 10], k = i)
class_agree <- table(result, heart_data[index_test,10])
sum_agree <- sum(diag(class_agree))
k_summary[i, 2] <- (ntest - sum_agree) / ntest
}
k_summary
dim(k_summary)
k_summary[1:10, ]
plot(k_summary)
######## NOT FINISHED ###################
minVal<-min(k_summary[,2])
minVal
minValueRow <- k_summary[k_summary[,2]==minVal, 1]
minValK<-minValueRow
minValK[1]
#Now we have the training and the test data, we are able to run knn. We begin with a value of k = 3:
resultValid1 <- knn(train, valid, cl = heart_data[index_train, 10], k=minValK[1])
resultValid1
#install.packages("sp")
library(sp)
knn.graph(resultValid1)
plot(valid[, ], col = as.factor(index_valid), pch = as.numeric(resultValid1))
#The inner command table(result, simT[index_test,3]) creates a table comparing the classification
#assigned to the test data by the k-nearest neighbour classifier against the true classification of the data
class_agree <- table(resultValid1, heart_data[index_valid,10])
class_agree
#The diag function selects the diagonal elements of the table, which is the number of points where knearest
#neighbour classification agrees with the true classification
sum_agree <- sum(diag(class_agree))
sum_agree
#remainder of the code ensures that the output that is returned is the percentage misclassification.
(nrow(test) - sum_agree) / nrow(test)
require(class)
?contour
?par
?par
